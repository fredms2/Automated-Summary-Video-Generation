{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_u9VSi2seE3"
      },
      "source": [
        "# **VISON+ - Enhanced Video Summarization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DtgkWSL70cp"
      },
      "source": [
        "Team Members:\n",
        "---\n",
        "- Balaji Bojadla\n",
        "- Mallikarjunarao Kovi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E8uhMibsWF2"
      },
      "source": [
        "\n",
        "# **Abstract**\n",
        "---\n",
        "Video summarization plays a crucial role in condensing lengthy videos into shorter versions while retaining key information. This project, titled VISON+ - Enhanced Video Summarization, aims to create comprehensive video summaries for long YouTube videos using both abstractive and extractive summarization techniques. By leveraging Natural Language Processing (NLP) pipelines and innovative video editing methods, VISON+ generates concise and informative summaries that capture the essence of the original content. This report outlines the methodology, techniques, and outcomes of the VISON+ project, along with a review of related work in the field of video summarization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUpvDpxd7_H7"
      },
      "source": [
        "\n",
        "# **Introduction**\n",
        "---\n",
        "Video content has become increasingly prevalent on online platforms such as YouTube, providing a vast repository of information and entertainment. However, the sheer volume of video content available poses challenges for viewers who may not have the time or patience to watch lengthy videos in their entirety. Video summarization addresses this challenge by condensing videos into shorter versions while preserving essential information.\n",
        "\n",
        "The project titled VISON+ - Enhanced Video Summarization aims to enhance the accessibility and usability of long YouTube videos by creating concise and informative video summaries. This project utilizes advanced techniques in abstractive and extractive summarization to generate comprehensive summaries that capture the essence of the original content. By combining these techniques with innovative video editing methods, VISON+ produces summary videos that offer quick insights into the content of lengthy videos.\n",
        "\n",
        "In this report, we present the methodology, techniques, and outcomes of the VISON+ project. We begin by discussing the data collection process and the tools used for video transcription. Next, we delve into the details of abstractive and extractive summarization techniques employed in the project. We also provide a review of related work in the field of video summarization, highlighting key contributions and methodologies from existing literature.\n",
        "\n",
        "Throughout the report, we use Markdown Cells to explain the outputs of our Code Cells, providing a clear and concise narrative of the project's methodology and outcomes. By leveraging advanced techniques in video summarization, VISON+ offers a novel approach to enhancing the accessibility and usability of long YouTube videos, paving the way for efficient consumption of video content in various domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR4Pjtftr7GB"
      },
      "source": [
        "\n",
        "# **Literature Review**\n",
        "---\n",
        "**Literature Review**\n",
        "\n",
        "Video summarization is a critical task in multimedia content analysis, aimed at condensing lengthy videos into shorter versions while retaining key information. In recent years, various approaches and techniques have been developed to address this challenge. In this literature review, we explore related work in the field of video summarization, highlighting key contributions and methodologies.\n",
        "\n",
        "1. **YouTube Transcript API**  \n",
        "   The YouTube Transcript API, developed by Depoix [1], provides a convenient way to access and extract transcripts from YouTube videos. This tool facilitates the retrieval of textual content from videos, which is essential for subsequent analysis and summarization tasks.\n",
        "\n",
        "   [1] GitHub Repository: [https://github.com/jdepoix/youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)\n",
        "\n",
        "2. **AI-Driven YouTube Video Generation**  \n",
        "   Oluyale [2] presents a comprehensive guide on generating YouTube videos using AI and machine learning techniques. The article discusses the use of NLP pipelines and summarization algorithms to generate concise and informative video content. This work provides insights into the application of AI in video content creation.\n",
        "\n",
        "   [2] Medium Article: [https://medium.com/@oluyaled/generate-youtube-video-using-ai-ml-python-c9ba9c86f9ea](https://medium.com/@oluyaled/generate-youtube-video-using-ai-ml-python-c9ba9c86f9ea)\n",
        "\n",
        "3. **Speech-to-Text Extraction from Video**  \n",
        "   GeeksforGeeks offers a tutorial on extracting speech-to-text from videos using Python [3]. This tutorial introduces techniques for converting audio content from videos into textual transcripts, which can be further analyzed and summarized using natural language processing algorithms.\n",
        "\n",
        "   [3] GeeksforGeeks Tutorial: [https://www.geeksforgeeks.org/extract-speech-text-from-video-in-python/](https://www.geeksforgeeks.org/extract-speech-text-from-video-in-python/)\n",
        "\n",
        "4. **Video Concatenation with MoviePy**  \n",
        "   The MoviePy library, as demonstrated by GeeksforGeeks [4], provides functionalities for concatenating multiple video files. This capability is crucial for assembling summary videos from segmented clips, allowing for the creation of concise and coherent video summaries.\n",
        "\n",
        "   [4] GeeksforGeeks Tutorial: [https://www.geeksforgeeks.org/moviepy-concatenating-multiple-video-files/](https://www.geeksforgeeks.org/moviepy-concatenating-multiple-video-files/)\n",
        "\n",
        "5. **Transformer-Based Text Summarization with Hugging Face**  \n",
        "   Hugging Face offers a suite of pre-trained transformer models fine-tuned for various NLP tasks, including text summarization [5]. These models leverage transformer architectures to generate concise summaries from textual input. The Hugging Face documentation provides comprehensive guidance on using these models for text summarization tasks.\n",
        "\n",
        "   [5] Hugging Face Summarization Documentation: [https://huggingface.co/docs/transformers/en/tasks/summarization](https://huggingface.co/docs/transformers/en/tasks/summarization)\n",
        "\n",
        "These references provide valuable insights and tools for the development and implementation of video summarization systems. By leveraging these resources and building upon existing methodologies, researchers and practitioners can continue to advance the field of multimedia content analysis and enhance the accessibility and usability of video content.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrM3VRzlCJgJ"
      },
      "source": [
        "**Training Procedure of Summarization Model**\n",
        "---\n",
        "The summarization model used in this project, \"sshleifer/distilbart-cnn-12-6\", is a pre-trained transformer model fine-tuned specifically for the task of text summarization. The training procedure for this model typically involves the following steps:\n",
        "\n",
        "1. **Data Collection:** The training data for the summarization model consists of a large corpus of text data, typically sourced from various sources such as news articles, blog posts, academic papers, and other publicly available textual content. The dataset should include pairs of input text and their corresponding summaries.\n",
        "\n",
        "2. **Preprocessing:** Before training the model, the training data undergoes preprocessing steps to clean and prepare it for the summarization task. This may include removing irrelevant content, tokenizing the text into individual words or subwords, and converting the text into numerical representations suitable for input into the model.\n",
        "\n",
        "3. **Model Architecture:** The summarization model is based on transformer architecture, which is a type of neural network architecture known for its effectiveness in handling sequential data. Transformers consist of multiple layers of self-attention mechanisms and feed-forward neural networks, allowing them to capture dependencies between words in the input text and generate coherent summaries.\n",
        "\n",
        "4. **Fine-tuning:** The pre-trained transformer model is fine-tuned on the specific task of text summarization using the training data. During fine-tuning, the model adjusts its parameters to minimize a loss function that measures the difference between the generated summaries and the ground truth summaries in the training data.\n",
        "\n",
        "5. **Evaluation:** After fine-tuning, the model is evaluated on a separate validation set to assess its performance in generating accurate and coherent summaries. Evaluation metrics such as ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores are commonly used to measure the quality of the generated summaries compared to the ground truth.\n",
        "\n",
        "6. **Deployment:** Once the model has been trained and evaluated satisfactorily, it can be deployed for use in summarizing new input text data. The deployed model accepts input text and generates concise summaries based on the learned patterns and associations in the training data.\n",
        "\n",
        "The summarization model \"sshleifer/distilbart-cnn-12-6\" utilized in this project has been trained on the BillSum dataset, provided by Hugging Face. The BillSum dataset is a collection of legislative bills and their summaries, sourced from various state legislatures in the United States.\n",
        "\n",
        "**BillSum Dataset Description:**\n",
        "- The BillSum dataset consists of pairs of legislative bills and their corresponding summaries, providing concise representations of the main points and key information contained within each bill.\n",
        "- Each sample in the dataset contains the full text of a legislative bill, along with its associated summary, which is typically a shorter version of the bill's contents.\n",
        "- The dataset covers a wide range of topics and legislative domains, including healthcare, education, transportation, and more, reflecting the diversity of legislative activity across different states.\n",
        "- The dataset is well-annotated, with high-quality summaries that accurately capture the essential information and key provisions of each bill.\n",
        "\n",
        "**Dataset Link:**\n",
        "- [BillSum Dataset](https://huggingface.co/datasets/billsum)\n",
        "\n",
        "The BillSum dataset serves as a valuable resource for training summarization models, providing rich and diverse text data that can be used to develop and evaluate the effectiveness of text summarization algorithms. By leveraging the BillSum dataset, the \"sshleifer/distilbart-cnn-12-6\" model has been fine-tuned to generate high-quality summaries across a variety of legislative contexts, making it well-suited for summarizing text from a wide range of domains and topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv5c5I_W0psW"
      },
      "source": [
        "**Data Collection:**\n",
        "---\n",
        "For the training of the Hugging Face model, we utilized a pre-existing dataset provided by Hugging Face called BillSum. The BillSum dataset contains pairs of legislative bills and their corresponding summaries, sourced from various state legislatures in the United States. This dataset serves as a valuable resource for training summarization models, providing rich and diverse text data suitable for the summarization task.\n",
        "\n",
        "**Data Cleaning:**\n",
        "---\n",
        "As the summarization model \"sshleifer/distilbart-cnn-12-6\" was pre-trained on the BillSum dataset, we did not perform explicit training in this project. Instead, we focused on preparing our data for inference with the pre-trained model. We obtained YouTube video transcripts using the YouTube Transcript API, which provided textual content from YouTube videos in the form of transcribed paragraphs.\n",
        "\n",
        "**Data Processing:**\n",
        "---\n",
        "After obtaining the transcribed paragraph text from the YouTube videos, we processed the data to ensure compatibility with the summarization model and to prepare it for generating the final summary video.\n",
        "\n",
        "Firstly, we converted the transcribed paragraphs into individual sentences or segments, as required by the summarization model. Each sentence or segment served as an input to the model for generating summaries.\n",
        "\n",
        "Next, we filtered the transcribed list by deleting sentences that were not presented in the summary paragraph. This step ensured that only relevant content was considered for summarization, improving the quality and relevance of the generated summary.\n",
        "\n",
        "Finally, we refined the output list of dictionaries by removing unnecessary fields such as the 'text' field, which contained the transcribed text. Instead, we retained only the 'start' and 'duration' fields, which provided information about the timing of each segment in the video. These fields were essential for splitting and merging the video segments to create the final summary video.\n",
        "\n",
        "By processing the transcribed data in this manner, we ensured that it was compatible with the summarization model and suitable for generating concise and informative summaries. Additionally, refining the output list of dictionaries allowed for efficient manipulation of video segments to produce the final summary video.\n",
        "\n",
        "**Description of YouTube Video Input, Text Extraction, and Summary Paragraph Output:**\n",
        "---\n",
        "- **YouTube Video Input**: The YouTube videos served as the source of content for the summarization task. These videos covered a wide range of topics and genres, ensuring diversity in the training data. The YouTube Transcript API facilitated the extraction of textual content from the videos, providing transcribed paragraphs for summarization.\n",
        "\n",
        "- **Text Extraction**: The text extraction process involved retrieving transcribed paragraphs from the YouTube videos using the YouTube Transcript API. Each transcribed paragraph represented the textual content of the video, providing input data for the summarization model.\n",
        "\n",
        "- **Summary Paragraph Output**: The output of the summarization process was a summary paragraph containing key sentences extracted from the transcribed video content. This summary paragraph condensed the original video content into a concise and informative summary, capturing the essence of the video in a shorter form.\n",
        "\n",
        "In this project, since the summarization model \"sshleifer/distilbart-cnn-12-6\" was pre-trained on the BillSum dataset, we focused on processing the cleaned and processed video transcript data into our preferred format for inference with the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj74D6ObO8c4",
        "outputId": "ce7d322f-158e-41bc-94ca-e18215b3dd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2025.11.12)\n",
            "Downloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-1.2.3\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=be74f27111455d4d343e667a0226192ecd832e302f850d691aca49f57ded395c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting pytextrank\n",
            "  Downloading pytextrank-3.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: GitPython>=3.1 in /usr/local/lib/python3.12/dist-packages (from pytextrank) (3.1.45)\n",
            "Requirement already satisfied: graphviz>=0.13 in /usr/local/lib/python3.12/dist-packages (from pytextrank) (0.21)\n",
            "Collecting icecream>=2.1 (from pytextrank)\n",
            "  Downloading icecream-2.1.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.12/dist-packages (from networkx[default]>=2.6->pytextrank) (3.6.1)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from pytextrank) (2.19.2)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from pytextrank) (1.16.3)\n",
            "Requirement already satisfied: spacy>=3.0 in /usr/local/lib/python3.12/dist-packages (from pytextrank) (3.8.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython>=3.1->pytextrank) (4.0.12)\n",
            "Collecting colorama>=0.3.9 (from icecream>=2.1->pytextrank)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting executing>=2.1.0 (from icecream>=2.1->pytextrank)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream>=2.1->pytextrank)\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from networkx[default]>=2.6->pytextrank) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from networkx[default]>=2.6->pytextrank) (3.10.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from networkx[default]>=2.6->pytextrank) (2.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.0->pytextrank) (25.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1->pytextrank) (5.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->networkx[default]>=2.6->pytextrank) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->networkx[default]>=2.6->pytextrank) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0->pytextrank) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0->pytextrank) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.0->pytextrank) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0->pytextrank) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0->pytextrank) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=3.0->pytextrank) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->networkx[default]>=2.6->pytextrank) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.0->pytextrank) (2.0.1)\n",
            "Downloading pytextrank-3.3.0-py3-none-any.whl (26 kB)\n",
            "Downloading icecream-2.1.8-py3-none-any.whl (15 kB)\n",
            "Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream, pytextrank\n",
            "Successfully installed asttokens-3.0.1 colorama-0.4.6 executing-2.2.1 icecream-2.1.8 pytextrank-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install langdetect\n",
        "!pip install pytube\n",
        "!pip install spacy\n",
        "!python3 -m spacy download en_core_web_lg\n",
        "!pip install pytextrank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8ItcIj1pS5ui"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary dependencies\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from langdetect import detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NL_ZQn5RTAEE"
      },
      "outputs": [],
      "source": [
        "def generate_summary(url, max_length=150):\n",
        "    \"\"\"\n",
        "    Summarizes the transcript of a YouTube video.\n",
        "\n",
        "    This function takes a YouTube video URL and an optional max_length parameter as inputs.\n",
        "    It first retrieves the transcript of the YouTube video.\n",
        "    If the transcript is longer than 3000 words, it uses extractive summarization (e.g. LSA).\n",
        "    Otherwise, it uses abstractive summarization.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): The URL of the YouTube video.\n",
        "    - max_length (int, optional): The maximum length of the summary. Defaults to 150.\n",
        "\n",
        "    Returns:\n",
        "    - str: The summarized transcript.\n",
        "    \"\"\"\n",
        "    # max_length = int(request.args.get('max_length', 150))\n",
        "    video_id = url.split('=')[1]\n",
        "    # video_id = \"IitIl2C3Iy8\"\n",
        "    # max_length = max(int(max_length), 150)\n",
        "\n",
        "    try:\n",
        "        transcript_list, transcript, length = get_transcript(video_id)\n",
        "        max_length = max(int(max_length), 150)\n",
        "    except:\n",
        "        return (\"\", \"No subtitles available for this video\", 404)\n",
        "\n",
        "    # Extractive summarization using LSA or Frequency-based method\n",
        "    # if len(transcript.split()) > 3000:\n",
        "    #     summary = extractive_summarization(transcript)\n",
        "    # else:\n",
        "    #     summary = abstractive_summarization(transcript, max_length)\n",
        "\n",
        "\n",
        "    summary = textrank(transcript)\n",
        "    return (transcript_list, summary, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dQtuuL8GE_Al"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "\n",
        "def textrank(transcript):\n",
        "  try:\n",
        "    nlp = spacy.load(\"en_core_web_lg\")\n",
        "    nlp.add_pipe(\"textrank\")\n",
        "    example_text = transcript\n",
        "    length = len(transcript.split(\".\"))\n",
        "    print('Original Document Size:', length)\n",
        "    doc = nlp(example_text)\n",
        "    summary = ''\n",
        "    limit_phrases = 2\n",
        "    limit_sentences = length // 3\n",
        "\n",
        "    print('SUmmary Document Size:', limit_sentences)\n",
        "\n",
        "\n",
        "\n",
        "    for sent in doc._.textrank.summary(limit_phrases=limit_phrases, limit_sentences=limit_sentences):\n",
        "      # print(sent)\n",
        "      summary = summary + str(sent)\n",
        "      # print('Summary Length:',len(sent))\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t-1XI_q8TDgo"
      },
      "outputs": [],
      "source": [
        "def is_transcript_english(transcript):\n",
        "    \"\"\"\n",
        "    Detect if the transcript is primarily in English.\n",
        "\n",
        "    :param transcript: The transcript text to be analyzed.\n",
        "    :return: True if the transcript is primarily in English, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        language = detect(transcript)\n",
        "        return language == 'en'\n",
        "\n",
        "    except Exception as e:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ItzvRubsTHja"
      },
      "outputs": [],
      "source": [
        "def get_transcript(video_id):\n",
        "    \"\"\"\n",
        "    Fetches and concatenates the transcript of a YouTube video.\n",
        "\n",
        "    Parameters:\n",
        "    video_id (str): The ID of the YouTube video.\n",
        "\n",
        "    Returns:\n",
        "    str: A string containing the concatenated transcript of the video.\n",
        "\n",
        "    Raises:\n",
        "    Exception: If there is an error in fetching the transcript.\n",
        "    \"\"\"\n",
        "    yy_api=YouTubeTranscriptApi()\n",
        "    try:\n",
        "        fetched_transcript = yy_api.fetch(video_id=video_id)\n",
        "        max_length = len(transcript_list)\n",
        "        transcript_lists = fetched_transcript.snippets\n",
        "        # for snippet in fetched_transcript:\n",
        "        #     # print(snippet.text)\n",
        "        #     transcript_lists.append(snippet.text)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        raise e\n",
        "\n",
        "\n",
        "    transcript = ' '.join([d.text for d in transcript_lists])\n",
        "\n",
        "    return transcript_lists, transcript, max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVA6u6-8Ta3u",
        "outputId": "cbd2ac38-8fa8-4b50-d847-b1e102f26765",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Document Size: 92\n",
            "SUmmary Document Size: 30\n",
            "here is Confident people celebrate the success\n",
            "of others rather than feeling threatened.Confident people support\n",
            "those around them.I vividly remember standing\n",
            "on the warning track of the baseball field 45 minutes before game time, looking at the opposing manager\n",
            "and his team wearing the wrong color uniform.Transcriber: Glenny Lapaix\n",
            "Reviewer: Vivian Lim When I was in high school, my mom asked me to order a pizza\n",
            "for the family on a Friday night.I looked up the number\n",
            "in the phone book and promptly handed the phone\n",
            "to my older brother to place the call.I was too shy to talk to a stranger.Fast-forward to college\n",
            "at the University of Illinois, my first time away from my small town.I spent the first several weeks\n",
            "crying in my dorm room, too homesick to partake\n",
            "in early freshman partying.The one frat party I did attend\n",
            "was so disappointing; I wanted to trade in my books,\n",
            "abandon my major and head back home to my small town.The confident behaviors I needed\n",
            "to pursue this dream were not yet available.And when I looked around\n",
            "at the confident students walking around me on campus, heads held high, pursuing a dream\n",
            "that they had set out to achieve, I wanted that kind of confidence too.But my behaviors did not align\n",
            "with these confident attitudes.Crying in my dorm room,\n",
            "shying away from social engagement, not showing up for class because I was worried\n",
            "others were smarter than me - these were not going to lead me\n",
            "to achieve my goal.So all I knew was that I needed to change.Research tells us that in order\n",
            "to get people to change, you need to not start with the attitudes, but with the behaviors\n",
            "associated with those attitudes.When people can see themselves\n",
            "behaving differently, they then begin to act differently.So the questions for me were, “Who am I?”“Who do I want to become?” and “How does this person\n",
            "I want to become behave?”The answers were that I wanted\n",
            "a successful career, one that meant something,\n",
            "allowed me to contribute.And for me, that was defined as a career\n",
            "as a sports executive.In order to achieve this goal,\n",
            "I needed to begin to act more confidently.And I did.Because 13 years later, I became\n",
            "the first female general manager of a Triple-A baseball team\n",
            "in nearly 20 years.(Cheers) Thank you.(Applause)I also went on to host\n",
            "the “Leadership is Female” podcast, where I’ve interviewed\n",
            "over 90 female executives in sports, an industry that’s over 80% male\n",
            "at management level and above.And time after time,\n",
            "these women have told me that the number one skill they’ve improved in order to earn their spot\n",
            "at the top of the sports industry is confidence.They, like me, did not possess\n",
            "this confidence necessary to increase their level\n",
            "in their career from the get-go.They had to work on the behaviors\n",
            "associated with this attitude in order to propel their career forward.So I’m here today to share with you six behaviors you can start today\n",
            "to increase your confidence.\n",
            "Summary of the YouTube video:\n",
            "***************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt the user to input the YouTube video URL and maximum length of the summary\n",
        "# url = input(\"Paste your YouTube video URL: \")\n",
        "# max_length = input(\"Enter maximum length of the summary (in sentences): \")\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=IitIl2C3Iy8\"\n",
        "max_length = 75\n",
        "\n",
        "# Call the function 'generate_summary' to generate the summary\n",
        "(transcript_list, summary_paragraph, status) = generate_summary(url, max_length)\n",
        "\n",
        "# Print a header for the summary\n",
        "print(\"Summary of the YouTube video:\\n***************************************************\\n\")\n",
        "\n",
        "# Display the summary paragraph\n",
        "# summary_paragraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2-qcREwErR2y",
        "outputId": "d8cd8242-71a5-43ed-ffe9-99908d4b7ff9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Transcriber: Glenny Lapaix\\nReviewer: Vivian Lim',\n",
              " 'When I was in high school,',\n",
              " 'my mom asked me to order a pizza\\nfor the family on a Friday night.',\n",
              " 'I looked up the number\\nin the phone book',\n",
              " 'and promptly handed the phone\\nto my older brother to place the call.',\n",
              " 'I was too shy to talk to a stranger.',\n",
              " 'Fast-forward to college\\nat the University of Illinois,',\n",
              " 'my first time away from my small town.',\n",
              " 'I spent the first several weeks\\ncrying in my dorm room,',\n",
              " 'too homesick to partake\\nin early freshman partying.',\n",
              " 'The one frat party I did attend\\nwas so disappointing;',\n",
              " 'I wanted to trade in my books,\\nabandon my major',\n",
              " 'and head back home to my small town.',\n",
              " 'The confident behaviors I needed\\nto pursue this dream',\n",
              " 'were not yet available.',\n",
              " 'And when I looked around\\nat the confident students',\n",
              " 'walking around me on campus,',\n",
              " 'heads held high, pursuing a dream\\nthat they had set out to achieve,',\n",
              " 'I wanted that kind of confidence too.',\n",
              " 'But my behaviors did not align\\nwith these confident attitudes.',\n",
              " 'Crying in my dorm room,\\nshying away from social engagement,',\n",
              " 'not showing up for class',\n",
              " 'because I was worried\\nothers were smarter than me -',\n",
              " 'these were not going to lead me\\nto achieve my goal.',\n",
              " 'So all I knew was that I needed to change.',\n",
              " 'Research tells us that in order\\nto get people to change,',\n",
              " 'you need to not start with the attitudes,',\n",
              " 'but with the behaviors\\nassociated with those attitudes.',\n",
              " 'When people can see themselves\\nbehaving differently,',\n",
              " 'they then begin to act differently.',\n",
              " 'So the questions for me were,',\n",
              " '“Who am I?”',\n",
              " '“Who do I want to become?”',\n",
              " 'and “How does this person\\nI want to become behave?”',\n",
              " 'The answers were that I wanted\\na successful career,',\n",
              " 'one that meant something,\\nallowed me to contribute.',\n",
              " 'And for me, that was defined as a career\\nas a sports executive.',\n",
              " 'In order to achieve this goal,\\nI needed to begin to act more confidently.',\n",
              " 'And I did.',\n",
              " 'Because 13 years later, I became\\nthe first female general manager',\n",
              " 'of a Triple-A baseball team\\nin nearly 20 years.',\n",
              " '(Cheers)',\n",
              " 'Thank you.',\n",
              " '(Applause)',\n",
              " 'I also went on to host\\nthe “Leadership is Female” podcast,',\n",
              " 'where I’ve interviewed\\nover 90 female executives in sports,',\n",
              " 'an industry that’s over 80% male\\nat management level and above.',\n",
              " 'And time after time,\\nthese women have told me',\n",
              " 'that the number one skill they’ve improved',\n",
              " 'in order to earn their spot\\nat the top of the sports industry',\n",
              " 'is confidence.',\n",
              " 'They, like me, did not possess\\nthis confidence necessary',\n",
              " 'to increase their level\\nin their career from the get-go.',\n",
              " 'They had to work on the behaviors\\nassociated with this attitude',\n",
              " 'in order to propel their career forward.',\n",
              " 'So I’m here today to share with you',\n",
              " 'six behaviors you can start today\\nto increase your confidence.',\n",
              " 'Why is it important\\nto increase our confidence?',\n",
              " 'Well, think of this:',\n",
              " 'How would you behave\\nor what could you achieve',\n",
              " 'if you were 10 times more confident?',\n",
              " 'Number one, count yourself in.',\n",
              " 'I spoke with a woman about her first time\\ndoing sideline reporting',\n",
              " 'at a nationally televised basketball game.',\n",
              " 'She was shaking in her heels,\\nstanding courtside,',\n",
              " 'nerves overtaking her until she heard\\nsomething familiar in her headset.',\n",
              " '“We’ll be on in five,\\nand three, two, one, you’re live.”',\n",
              " 'And she performed with excellence.',\n",
              " 'The nerves melted away.',\n",
              " 'She’s an athlete, a former basketball\\nplayer used to performing on the court',\n",
              " 'by the clock.',\n",
              " 'And the tactic remained true.',\n",
              " 'Counting will get you started,\\nand momentum will keep you going.',\n",
              " 'I have used this technique.',\n",
              " 'I’ve had more uncomfortable\\nconversations than I care to recall,',\n",
              " 'but one I’ll share with you today.',\n",
              " 'I vividly remember standing\\non the warning track of the baseball field',\n",
              " '45 minutes before game time,',\n",
              " 'looking at the opposing manager\\nand his team wearing',\n",
              " 'the wrong color uniform.',\n",
              " 'I wanted to turn and run back up\\nto my office and hide.',\n",
              " 'But instead, faced him head-on,',\n",
              " 'and I said in my mind,\\n“Three, two, one, go.”',\n",
              " 'And I started walking towards him.',\n",
              " 'And when I arrived, we had\\na very uncomfortable conversation',\n",
              " 'about his team wearing\\nthe wrong color uniform.',\n",
              " 'Yes, I had to ask these grown men\\nto change their clothes.',\n",
              " 'It was so awkward.',\n",
              " 'But when I asked myself,\\n“Who am I? And how do I behave?”',\n",
              " 'The answer was that I’m a person\\nwho’s not too shy to stand up',\n",
              " 'for what I believe, what is right\\nand stand up to conflict.',\n",
              " 'Counting got me started,\\nand momentum kept me going.',\n",
              " 'Number two, what if you only had\\nto be brave for a total of 20 seconds?',\n",
              " 'Give yourself 20 seconds of courage.',\n",
              " 'This behavior helped me enormously',\n",
              " 'when I published my podcast\\n“Leadership is Female,”',\n",
              " 'bold title and all,',\n",
              " 'for all the world to see, hear,\\ncritique and have their opinions.',\n",
              " 'I vividly remember sitting\\non the carpet of my closet floor,',\n",
              " 'holding my computer,\\nlooking at the “Upload” button,',\n",
              " 'thinking to myself,',\n",
              " '“Does it need any more edits?\\nShould I listen to it one more time?”',\n",
              " 'And I told myself, “Emily,\\ngive yourself 20 seconds of courage.”',\n",
              " 'And I hit “Publish,” and it was done.',\n",
              " 'And guess what?',\n",
              " 'I kept breathing,\\nand the world kept turning.',\n",
              " 'And the podcast grew\\ninto what it was meant to be.',\n",
              " 'All because of 20 seconds of courage.',\n",
              " 'Number three, take a seat at the table.',\n",
              " 'Not metaphorically speaking;',\n",
              " 'actually, take a seat at the table.',\n",
              " 'I spoke with a woman who represents\\nsome of the biggest names in baseball,',\n",
              " 'and she told me a story\\nabout taking a seat at the table.',\n",
              " 'She noticed women waiting\\naround the edges of the room,',\n",
              " 'waiting for the seats to be filled.',\n",
              " 'And worse yet, she was doing it too.',\n",
              " 'In order to become the more confident\\nwoman that she envisioned herself to be,',\n",
              " 'she needed to go in, sit down,\\nspeak her mind and get the deal done.',\n",
              " 'That started with one simple action:',\n",
              " 'Taking a seat at the table.',\n",
              " 'Number four, cheer for other\\npeople’s success.',\n",
              " 'They say that women will pull up\\nthe ladder behind them.',\n",
              " 'What if you didn’t?',\n",
              " 'What if you extended a hand back\\nto lead her forward?',\n",
              " 'What if you celebrated\\nthe success of a colleague',\n",
              " 'rather than feeling sorry\\nfor yourself that it was not you',\n",
              " 'accepting the accolades?',\n",
              " 'Confident people celebrate the success\\nof others rather than feeling threatened.',\n",
              " 'Think of this great quote\\nfrom Amy Poehler:',\n",
              " '“Good for her,',\n",
              " 'not for me.”',\n",
              " 'It turns that pit in your stomach\\nof “Oh, she did that? And I’m still here.”',\n",
              " 'into “Yes! Good for her! Not for me.”',\n",
              " 'This is her celebration, not mine.',\n",
              " 'And when my time comes,',\n",
              " 'isn’t it going to be great to have\\nthe support of so many people around me?',\n",
              " 'Wins are so much better\\ncelebrated together.',\n",
              " 'Join in; cheer someone else on.',\n",
              " 'Here’s number four in action:',\n",
              " 'Recently, a woman was promoted\\nto chief marketing officer',\n",
              " 'of a major sports league.',\n",
              " 'The offer to interview\\nand ultimately land the job',\n",
              " 'came after her public celebration\\nand sincere congratulatory outreach',\n",
              " 'to the newly named\\nfemale league president.',\n",
              " 'Confident people support\\nthose around them.',\n",
              " 'Cheer for someone else’s success.',\n",
              " 'Number five, bolster your\\nconfidence for a new activity',\n",
              " 'through your already\\ngreat performance in another.',\n",
              " 'What are you really good at?',\n",
              " 'What is easier today\\nthan it was one year ago?',\n",
              " 'What is your most proud accomplishment?',\n",
              " 'Answer those questions.\\nThink about those answers.',\n",
              " 'Those answers are\\nwhere your confidence is born.',\n",
              " 'Confidence is born\\nin all we’ve already done',\n",
              " 'and already achieved.',\n",
              " 'Recently, a woman I interviewed\\non the “Leadership is Female” podcast',\n",
              " 'was going after a big,\\nbig promotion at a top team.',\n",
              " 'Before she went in to pitch to her boss,',\n",
              " 'she reviewed her current job description,',\n",
              " 'made notes of her accolades\\nin all areas mentioned,',\n",
              " 'and then was prepared\\nwith examples and the confidence',\n",
              " 'of the success she had in the past.',\n",
              " 'She got the promotion.',\n",
              " 'Use your prior success\\nto propel yourself forward.',\n",
              " 'And number six, celebrate constantly.',\n",
              " 'How often do we reach our goals\\nand then just immediately move on?',\n",
              " 'When we do this, the recollection\\nof that success is diminished.',\n",
              " 'How can we confidently move forward\\nif we can’t remember what we achieved,',\n",
              " 'or worse yet,',\n",
              " 'link that accomplishment to stress?',\n",
              " 'Find ways to celebrate\\nthat are meaningful to you,',\n",
              " 'like creating a highlight reel\\non your cell phone',\n",
              " 'of your most proud accomplishments.',\n",
              " 'Take your team out for celebratory drinks\\nwhen you close the big deal.',\n",
              " 'Buy yourself a massage\\nor maybe order a pizza',\n",
              " 'when you reach your personal goals.',\n",
              " 'It doesn’t matter how you celebrate;\\nit matters that you do.',\n",
              " 'This will create a marker in your brain\\nto rewire and reinforce the behaviors',\n",
              " 'that led to success in the first place.',\n",
              " 'I’ve come a long way from the girl\\nwho couldn’t order a pizza',\n",
              " 'to the woman who became GM\\nof a minor league baseball team,',\n",
              " 'started a podcast\\nand delivered a TEDx talk.',\n",
              " 'All because I made the decision\\nto become a more confident person.',\n",
              " 'And I hope you do too.',\n",
              " 'Because how many runs could you score\\nif you were 10 times more confident?',\n",
              " 'Thank you.',\n",
              " '(Applause) (Cheers)']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCVUHhlxdCVg",
        "outputId": "e1c0e267-0995-494c-a98f-21c6206d45dd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FetchedTranscriptSnippet(text='Transcriber: Glenny Lapaix\\nReviewer: Vivian Lim', start=0.0, duration=7.0),\n",
              " FetchedTranscriptSnippet(text='When I was in high school,', start=15.445, duration=1.302),\n",
              " FetchedTranscriptSnippet(text='my mom asked me to order a pizza\\nfor the family on a Friday night.', start=16.747, duration=3.57),\n",
              " FetchedTranscriptSnippet(text='I looked up the number\\nin the phone book', start=20.751, duration=1.868),\n",
              " FetchedTranscriptSnippet(text='and promptly handed the phone\\nto my older brother to place the call.', start=22.619, duration=3.203),\n",
              " FetchedTranscriptSnippet(text='I was too shy to talk to a stranger.', start=25.889, duration=2.67),\n",
              " FetchedTranscriptSnippet(text='Fast-forward to college\\nat the University of Illinois,', start=28.959, duration=2.636),\n",
              " FetchedTranscriptSnippet(text='my first time away from my small town.', start=31.895, duration=2.302),\n",
              " FetchedTranscriptSnippet(text='I spent the first several weeks\\ncrying in my dorm room,', start=34.231, duration=2.869),\n",
              " FetchedTranscriptSnippet(text='too homesick to partake\\nin early freshman partying.', start=37.334, duration=3.103),\n",
              " FetchedTranscriptSnippet(text='The one frat party I did attend\\nwas so disappointing;', start=40.837, duration=3.904),\n",
              " FetchedTranscriptSnippet(text='I wanted to trade in my books,\\nabandon my major', start=44.741, duration=2.403),\n",
              " FetchedTranscriptSnippet(text='and head back home to my small town.', start=47.144, duration=1.802),\n",
              " FetchedTranscriptSnippet(text='The confident behaviors I needed\\nto pursue this dream', start=50.08, duration=3.103),\n",
              " FetchedTranscriptSnippet(text='were not yet available.', start=53.283, duration=1.368),\n",
              " FetchedTranscriptSnippet(text='And when I looked around\\nat the confident students', start=54.718, duration=2.636),\n",
              " FetchedTranscriptSnippet(text='walking around me on campus,', start=57.354, duration=1.835),\n",
              " FetchedTranscriptSnippet(text='heads held high, pursuing a dream\\nthat they had set out to achieve,', start=59.323, duration=4.871),\n",
              " FetchedTranscriptSnippet(text='I wanted that kind of confidence too.', start=64.294, duration=2.236),\n",
              " FetchedTranscriptSnippet(text='But my behaviors did not align\\nwith these confident attitudes.', start=66.797, duration=3.804),\n",
              " FetchedTranscriptSnippet(text='Crying in my dorm room,\\nshying away from social engagement,', start=70.834, duration=3.237),\n",
              " FetchedTranscriptSnippet(text='not showing up for class', start=74.204, duration=1.301),\n",
              " FetchedTranscriptSnippet(text='because I was worried\\nothers were smarter than me -', start=75.505, duration=2.403),\n",
              " FetchedTranscriptSnippet(text='these were not going to lead me\\nto achieve my goal.', start=77.975, duration=2.636),\n",
              " FetchedTranscriptSnippet(text='So all I knew was that I needed to change.', start=80.644, duration=2.736),\n",
              " FetchedTranscriptSnippet(text='Research tells us that in order\\nto get people to change,', start=83.981, duration=2.936),\n",
              " FetchedTranscriptSnippet(text='you need to not start with the attitudes,', start=87.017, duration=2.803),\n",
              " FetchedTranscriptSnippet(text='but with the behaviors\\nassociated with those attitudes.', start=89.82, duration=3.57),\n",
              " FetchedTranscriptSnippet(text='When people can see themselves\\nbehaving differently,', start=93.557, duration=3.036),\n",
              " FetchedTranscriptSnippet(text='they then begin to act differently.', start=96.693, duration=3.07),\n",
              " FetchedTranscriptSnippet(text='So the questions for me were,', start=100.364, duration=1.534),\n",
              " FetchedTranscriptSnippet(text='“Who am I?”', start=102.399, duration=1.001),\n",
              " FetchedTranscriptSnippet(text='“Who do I want to become?”', start=103.9, duration=1.469),\n",
              " FetchedTranscriptSnippet(text='and “How does this person\\nI want to become behave?”', start=105.869, duration=3.137),\n",
              " FetchedTranscriptSnippet(text='The answers were that I wanted\\na successful career,', start=109.673, duration=2.669),\n",
              " FetchedTranscriptSnippet(text='one that meant something,\\nallowed me to contribute.', start=112.342, duration=3.404),\n",
              " FetchedTranscriptSnippet(text='And for me, that was defined as a career\\nas a sports executive.', start=115.746, duration=3.837),\n",
              " FetchedTranscriptSnippet(text='In order to achieve this goal,\\nI needed to begin to act more confidently.', start=120.083, duration=5.372),\n",
              " FetchedTranscriptSnippet(text='And I did.', start=126.156, duration=1.001),\n",
              " FetchedTranscriptSnippet(text='Because 13 years later, I became\\nthe first female general manager', start=127.424, duration=3.87),\n",
              " FetchedTranscriptSnippet(text='of a Triple-A baseball team\\nin nearly 20 years.', start=131.361, duration=3.57),\n",
              " FetchedTranscriptSnippet(text='(Cheers)', start=135.532, duration=1.001),\n",
              " FetchedTranscriptSnippet(text='Thank you.', start=136.533, duration=1.001),\n",
              " FetchedTranscriptSnippet(text='(Applause)', start=137.534, duration=1.135),\n",
              " FetchedTranscriptSnippet(text='I also went on to host\\nthe “Leadership is Female” podcast,', start=141.405, duration=3.169),\n",
              " FetchedTranscriptSnippet(text='where I’ve interviewed\\nover 90 female executives in sports,', start=144.574, duration=4.071),\n",
              " FetchedTranscriptSnippet(text='an industry that’s over 80% male\\nat management level and above.', start=148.712, duration=4.338),\n",
              " FetchedTranscriptSnippet(text='And time after time,\\nthese women have told me', start=153.25, duration=2.502),\n",
              " FetchedTranscriptSnippet(text='that the number one skill they’ve improved', start=155.819, duration=2.536),\n",
              " FetchedTranscriptSnippet(text='in order to earn their spot\\nat the top of the sports industry', start=158.355, duration=3.503),\n",
              " FetchedTranscriptSnippet(text='is confidence.', start=162.092, duration=1.168),\n",
              " FetchedTranscriptSnippet(text='They, like me, did not possess\\nthis confidence necessary', start=163.894, duration=4.771),\n",
              " FetchedTranscriptSnippet(text='to increase their level\\nin their career from the get-go.', start=168.899, duration=3.603),\n",
              " FetchedTranscriptSnippet(text='They had to work on the behaviors\\nassociated with this attitude', start=172.969, duration=3.904),\n",
              " FetchedTranscriptSnippet(text='in order to propel their career forward.', start=176.873, duration=2.57),\n",
              " FetchedTranscriptSnippet(text='So I’m here today to share with you', start=179.976, duration=2.002),\n",
              " FetchedTranscriptSnippet(text='six behaviors you can start today\\nto increase your confidence.', start=181.978, duration=5.072),\n",
              " FetchedTranscriptSnippet(text='I vividly remember standing\\non the warning track of the baseball field', start=244.674, duration=3.804),\n",
              " FetchedTranscriptSnippet(text='45 minutes before game time,', start=248.645, duration=1.969),\n",
              " FetchedTranscriptSnippet(text='looking at the opposing manager\\nand his team wearing', start=250.881, duration=2.769),\n",
              " FetchedTranscriptSnippet(text='the wrong color uniform.', start=253.65, duration=1.768),\n",
              " FetchedTranscriptSnippet(text='Confident people celebrate the success\\nof others rather than feeling threatened.', start=406.703, duration=5.939),\n",
              " FetchedTranscriptSnippet(text='Confident people support\\nthose around them.', start=462.025, duration=3.537),\n",
              " FetchedTranscriptSnippet(text='Thank you.', start=602.365, duration=1.001)]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Define a function to match text in a paragraph with text in a list of JSON objects\n",
        "def match_text_in_json(paragraph, json_list):\n",
        "    matched_list = []\n",
        "    # Iterate over each JSON object in the list\n",
        "    for obj in json_list:\n",
        "        # Check if the text of the JSON object (case-insensitive) is present in the paragraph\n",
        "        if obj.text.lower() in paragraph.lower():\n",
        "            # If a match is found, append the JSON object to the matched list\n",
        "            matched_list.append(obj)\n",
        "    return matched_list\n",
        "\n",
        "# SUmmary paragraph paragraph to search for matches\n",
        "paragraph = summary_paragraph\n",
        "\n",
        "# transcript  list of JSON objects\n",
        "json_list = transcript_list\n",
        "\n",
        "# Call the function to find JSON objects that match text in the paragraph\n",
        "matched_json = match_text_in_json(paragraph, json_list)\n",
        "\n",
        "# Print the matched JSON objects\n",
        "matched_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1hALeyCiq2W",
        "outputId": "ed4b10fd-dfe6-4c13-f67b-5aec24a28eb7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'start': 0.0, 'duration': 7.0},\n",
              " {'start': 15.445, 'duration': 33.501},\n",
              " {'start': 50.08, 'duration': 88.589},\n",
              " {'start': 141.405, 'duration': 45.64500000000001},\n",
              " {'start': 244.674, 'duration': 10.744},\n",
              " {'start': 406.703, 'duration': 5.939},\n",
              " {'start': 462.025, 'duration': 3.537},\n",
              " {'start': 602.365, 'duration': 1.001}]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "def merge_dicts(input_list):\n",
        "\n",
        "    '''\n",
        "    This function, merge_dicts, takes a list of dictionaries input_list as input, where each dictionary represents\n",
        "    a segment with keys 'start' and 'duration'. The function merges overlapping segments within the list, ensuring\n",
        "    that no two segments overlap in time.\n",
        "    '''\n",
        "    output_list = []\n",
        "    n = len(input_list)\n",
        "    i = 0\n",
        "\n",
        "    while i < n:\n",
        "        current_segment = input_list[i]\n",
        "        j = i + 1\n",
        "\n",
        "        while j < n and current_segment.start + current_segment.duration + 1 >= input_list[j].start:\n",
        "            # Merge overlapping segments\n",
        "            current_segment.duration = input_list[j].start - current_segment.start + input_list[j].duration\n",
        "            j += 1\n",
        "\n",
        "        output_list.append({'start': current_segment.start, 'duration': current_segment.duration})\n",
        "        i = j\n",
        "\n",
        "    return output_list\n",
        "    return merged_list\n",
        "\n",
        "# Sample input\n",
        "input_list = matched_json\n",
        "\n",
        "# Call the function and print the output\n",
        "merged_matched_json = merge_dicts(input_list)\n",
        "#Print the merged output list\n",
        "merged_matched_json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytubefix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Uq8JdfxrLj",
        "outputId": "413952b7-fe60-4c34-cae3-765d96b0ad57"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytubefix\n",
            "  Downloading pytubefix-10.3.6-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohttp>=3.12.13 in /usr/local/lib/python3.12/dist-packages (from pytubefix) (3.13.2)\n",
            "Collecting nodejs-wheel-binaries>=22.20.0 (from pytubefix)\n",
            "  Downloading nodejs_wheel_binaries-24.12.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.12.13->pytubefix) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.11)\n",
            "Downloading pytubefix-10.3.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodejs_wheel_binaries-24.12.0-py2.py3-none-manylinux_2_28_x86_64.whl (60.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nodejs-wheel-binaries, pytubefix\n",
            "Successfully installed nodejs-wheel-binaries-24.12.0 pytubefix-10.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yt_dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgcNiB3l0WL8",
        "outputId": "45ef3d83-ec86-4dca-a200-984d2f924022"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.12.8-py3-none-any.whl.metadata (180 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/180.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.12.8-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt_dlp\n",
            "Successfully installed yt_dlp-2025.12.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUzq0uHjTzGe",
        "outputId": "00950462-3952-40e8-aedd-691a2e1b2c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How to be confident (even if you’re not) | Montana von Fliss | TEDxBellevueWomen\n"
          ]
        }
      ],
      "source": [
        "from pytubefix import YouTube\n",
        "from pytube.exceptions import RegexMatchError\n",
        "from pytubefix.cli import on_progress\n",
        "\n",
        "# Create a YouTube object by passing the video URL\n",
        "# url = \"https://www.youtube.com/watch?v=eVFzbxmKNUw\"\n",
        "try:\n",
        "  yt = YouTube(url, on_progress_callback = on_progress, use_oauth=True)\n",
        "  print(yt.title)\n",
        "\n",
        "  ys = yt.streams.get_highest_resolution()\n",
        "  ys.download(filename='original_video.mp4')\n",
        "\n",
        "except RegexMatchError:\n",
        "    print(\"Invalid YouTube URL or pytube failed. Try updating pytube.\")\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAu138ZgT24X",
        "outputId": "e5428087-f36d-4fce-dad4-0176d86a3e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<moviepy.video.io.VideoFileClip.VideoFileClip object at 0x7b54b52ab380>\n",
            "Moviepy - Building video final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_video.mp4\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "# Load the original video\n",
        "original_video = VideoFileClip(\"original_video.mp4\")\n",
        "\n",
        "# List of start positions and durations\n",
        "video_segments = merged_matched_json\n",
        "\n",
        "# List to store cut video clips\n",
        "cut_clips = []\n",
        "\n",
        "# Cut the video based on segments\n",
        "for segment in video_segments:\n",
        "    start_time = segment[\"start\"]\n",
        "    duration = segment[\"duration\"]\n",
        "    end_time = start_time + duration\n",
        "\n",
        "    # Cut the segment from the original video\n",
        "    cut_clip = original_video.subclip(start_time, end_time)\n",
        "    cut_clips.append(cut_clip)\n",
        "\n",
        "print(cut_clip)\n",
        "# Concatenate all the cut clips\n",
        "final_video = concatenate_videoclips(cut_clips)\n",
        "\n",
        "\n",
        "# Export the final video\n",
        "final_video.write_videofile(\"final_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "video_path = \"final_video.mp4\"\n",
        "clip = VideoFileClip(video_path)\n",
        "print(clip.duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zBfL3Z13PPQ",
        "outputId": "19b37098-9c39-44d1-e3f0-34f3f41b916c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "195.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "resources": {
            "http://localhost:8080/final_video.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "height": 171
        },
        "id": "6Jre60pnUont",
        "outputId": "7b90ed3f-dd23-4632-f653-d715be1afdfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"final_video.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "# final_video.mp4 is in the current directory\n",
        "video_path = \"final_video.mp4\"\n",
        "\n",
        "# Display the video\n",
        "Video(video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEH-3gTx31U5"
      },
      "source": [
        "**Evaluation**\n",
        "---\n",
        "\n",
        "----\n",
        "In order to evaluate the effectiveness of the summarization model, I conducted a test with Ms. Boddu Kavya, a MSIT student at the University of Cincinnati. Ms. Kavya was provided with an original video approximately 11 minutes long titled **\"*Six behaviors to increase your confidence | Emily Jaenson | TEDxReno*\"**. Subsequently, she was shown the summary video of 3 minutes long generated by the project.\n",
        "\n",
        "Ms. Kavya provided positive feedback on the summarization features, stating that most of the significant information from the original video was covered in the summary video. She scored the model with a rating of 90 out of 100, indicating a high level of satisfaction with the summarization output. Additionally, she mentioned that by using the model's output on other videos, she was able to save a significant amount of time by referring to the summary videos.\n",
        "\n",
        "However, Ms. Kavya also noted that while the summary videos were helpful for revision purposes, they may not be solely dependable for study purposes, as some important information may be left out by the model. Nonetheless, she expressed confidence in using the model for revision and quick reference purposes.\n",
        "\n",
        "Overall, the evaluation results indicate that the summarization model effectively condenses lengthy videos into concise summaries, capturing the essential information and providing users with a valuable tool for efficient content consumption. Further refinements and enhancements to the model could potentially improve its performance and utility for a wider range of applications.\n",
        "\n",
        "----\n",
        "In order to ensure the authenticity of the evalution / feedback section, here are the contact details of the evaluator:\n",
        "\n",
        "Evaluator Information:\n",
        "\n",
        "- Name: Boddu Kavya\n",
        "- Email: bodduka@mail.uc.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQQa9vXj1q-B"
      },
      "source": [
        "**Results and Conclusions**\n",
        "---\n",
        "\n",
        "---\n",
        "The project successfully achieved its goal of generating short YouTube videos using the MoviePy library based on the filtered transcript list. By extracting timestamps from the filtered transcript list, we were able to accurately segment the original video and concatenate these segments to create a concise summary video.\n",
        "\n",
        "The summarization process involved filtering the transcript list to include only sentences present in the summary paragraph. This ensured that the generated summary video captured the most important aspects of the original content. The timestamps extracted from the filtered transcript list served as the basis for cutting and concatenating video segments, resulting in a coherent summary video.\n",
        "\n",
        "Through this approach, we effectively condensed lengthy YouTube videos into shorter, more digestible summaries, making it easier for viewers to grasp the key points without having to watch the entire video. This has significant implications for content creators, educators, and consumers alike, as it allows for more efficient consumption and dissemination of video content.\n",
        "\n",
        "In conclusion, the project demonstrates the feasibility and effectiveness of using automated summarization techniques to generate concise video summaries. By leveraging tools such as the MoviePy library and filtering techniques based on transcript analysis, we can streamline the process of summarizing video content and enhance its accessibility and usability for a wide range of audiences. This project lays the foundation for future research and development in the field of video summarization, paving the way for more advanced and sophisticated approaches to content summarization and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKHkXKlUmNhr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}